## Machine-Learning-Laboratory
Machine Learning using Jupyter Notebook and Python to solve the lab tasks.

## How to run
-----------------------------------
![image](https://user-images.githubusercontent.com/72825756/197519913-6435e6d3-7e06-4264-a6ef-98e93375faf1.png)


## Task details
-----------------------------------
**Linear Regression Lab:** Predict the consumption (Fuel Efficiency variable) of a car starting from the following data set: https://www.kaggle.com/datasets/anushabellam/cars-cars-2

**Decision Trees Lab:** Predict the position within the company (job role) starting from the following dataset: https://www.kaggle.com/esmaeil391/ibm-hr
 Implement the possibility of classifying a single instance read from the file or from the keyboard. 
 
 **Naive Bayes Lab:** Predict the review(positive or negative) starting grom the data set: https://www.kaggle.com/datasets/team-ai/spam-text-message-classification 
 Use a decision tree algorithm for experiments in addition to Naive Bayes.
 
 **Clustering Lab:** Compare at least 2 clustering algorithms on the dataset: https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python
 Use two methods of data visualization. What metrics did you use for comparison?
 
**PCA Lab:** Evaluate the impact that the application of the PCA algorithm has on the dataset: https://www.kaggle.com/datasets/crawford/gene-expression  Gradually reduce the number of attributes and use a classification algorithm to evaluate performance at each step. 

**Ensemble Lab:** For the MNIST dataset (https://www.kaggle.com/oddrationale/mnist-in-csv), please predict the number (label column) using at least one ensemble algorithm and another classical algorithm. Compare both the accuracy and the training time (possibly also validation) for the two algorithms.
 
## Resources
---------------------------------------
https://www.kaggle.com/code/pragyanbo/ensemble-learning-methods-using-titanic-dataset/notebook

https://www.kaggle.com/code/fengdanye/machine-learning-6-basic-ensemble-learning/notebook

https://www.kaggle.com/code/amrmahmoud123/1-guide-to-ensembling-methods/notebook

https://www.kaggle.com/code/nirajvermafcb/principal-component-analysis-explained/notebook

https://www.kaggle.com/code/rangarirb/pca-tutorial/notebook

https://github.com/PPStef/invatare-automata-lab/tree/master/7.%20Algoritmi%20pentru%20reducerea%20numarului%20de%20atribute 

https://www.geeksforgeeks.org/k-means-clustering-introduction/

https://www.w3schools.com/python/python_ml_hierarchial_clustering.asp

https://github.com/PPStef/invatare-automata-lab/tree/master/5.%20Clustering

https://www.geeksforgeeks.org/naive-bayes-classifiers/

https://github.com/PPStef/invatare-automata-lab/tree/master/4.%20Clasificatoare/Clasificatoare%20Bayesiene

https://www.geeksforgeeks.org/decision-tree-implementation-python/

https://medium.com/@mer423/decision-tree-visualization-e82dc6d5bf9c

https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052

https://github.com/PPStef/invatare-automata-lab/tree/master/3.%20Arbori%20de%20decizie

https://github.com/PPStef/invatare-automata-lab/tree/master/2.%20Regresie%20Liniara%20si%20Logistica

https://jupyter-notebook.readthedocs.io/en/latest/

https://github.com/AndreeaDraghici/Learning-basics-Jupyter-Notebook
